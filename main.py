import os
import re
from datetime import datetime, timezone, timedelta

import requests
from bs4 import BeautifulSoup

ALS_RANKED_URL = "https://apexlegendsstatus.com/current-map/battle_royale/ranked"
ALS_ASSET_BASE = "https://apexlegendsstatus.com/assets/maps/"

# è‹±èªãƒãƒƒãƒ—å â†’ æ—¥æœ¬èªè¡¨è¨˜ï¼ˆå¥½ã¿ã§å¢—ã‚„ã—ã¦OKï¼‰
JA_MAP = {
    "Olympus": "ã‚ªãƒªãƒ³ãƒ‘ã‚¹",
    "Storm Point": "ã‚¹ãƒˆãƒ¼ãƒ ãƒã‚¤ãƒ³ãƒˆ",
    "World's Edge": "ãƒ¯ãƒ¼ãƒ«ã‚ºã‚¨ãƒƒã‚¸",
    "Worlds Edge": "ãƒ¯ãƒ¼ãƒ«ã‚ºã‚¨ãƒƒã‚¸",
    "Broken Moon": "ãƒ–ãƒ­ãƒ¼ã‚¯ãƒ³ãƒ ãƒ¼ãƒ³",
    "Kings Canyon": "ã‚­ãƒ³ã‚°ã‚¹ã‚­ãƒ£ãƒ‹ã‚ªãƒ³",
    "E-District": "E-ãƒ‡ã‚£ã‚¹ãƒˆãƒªã‚¯ãƒˆ",
}

USER_AGENT = "Mozilla/5.0 (compatible; ApexRankMapDiscordNotifier/1.0; +https://github.com/)"


ALS_ALL_MODES_URL = "https://apexlegendsstatus.com/current-map"  # â† ã“ã‚Œã‚’å®šæ•°ã‚¨ãƒªã‚¢ã«è¿½åŠ ã—ã¦OK

def _normalize_lines(html: str) -> list[str]:
    soup = BeautifulSoup(html, "html.parser")
    text = soup.get_text("\n")

    lines: list[str] = []
    for ln in text.splitlines():
        # NBSPãªã©ã€Œè¦‹ãŸç›®åŒã˜ç©ºç™½ã€ã‚’æ™®é€šã®ç©ºç™½ã¸
        ln = ln.replace("\xa0", " ").replace("\u202f", " ").strip()
        if ln:
            lines.append(ln)
    return lines


def fetch_ranked_rotation():
    """
    1) rankedå°‚ç”¨ãƒšãƒ¼ã‚¸ã‹ã‚‰æŠ½å‡ºï¼ˆä¸€è¦§ã®å…ˆé ­ï¼ç¾åœ¨ã€2ç•ªç›®ï¼æ¬¡ï¼‰
    2) å–ã‚Œãªã„å ´åˆã¯ /current-map ã® BR Ranked ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰æŠ½å‡ºï¼ˆä¿é™ºï¼‰
    """
    # --- (1) rankedå°‚ç”¨ãƒšãƒ¼ã‚¸ ---
    r = requests.get(
        ALS_RANKED_URL,
        timeout=25,
        headers={"User-Agent": USER_AGENT},
    )
    r.raise_for_status()

    lines = _normalize_lines(r.text)

    entries = []
    for i, ln in enumerate(lines):
        if i == 0:
            continue

        # â˜…ã“ã“ãŒä¿®æ­£ç‚¹ï¼š "From " ã§ã¯ãªã "from" ã§å§‹ã¾ã‚‹ã‹ï¼ˆã‚¹ãƒšãƒ¼ã‚¹ä¸è¦ï¼‰
        if ln.lower().startswith("from"):
            name = lines[i - 1].strip()
            name = re.sub(r"^#+\s*", "", name).strip()  # å¿µã®ãŸã‚
            entries.append({"name": name, "detail": ln})

    if entries:
        current = entries[0]
        next_map = entries[1] if len(entries) >= 2 else None
        return current, next_map

    # --- (2) ä¿é™ºï¼š/current-map ã® BR Ranked ã‹ã‚‰æ‹¾ã† ---
    r = requests.get(
        ALS_ALL_MODES_URL,
        timeout=25,
        headers={"User-Agent": USER_AGENT},
    )
    r.raise_for_status()
    lines = _normalize_lines(r.text)

    idx = next((i for i, l in enumerate(lines) if l.lower() == "br ranked"), None)
    if idx is None or idx + 1 >= len(lines):
        sample = "\n".join(lines[:80])
        raise RuntimeError("BR Ranked ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n---DEBUG---\n" + sample)

    current_name = lines[idx + 1]
    current_from = next((l for l in lines[idx + 2 : idx + 20] if l.lower().startswith("from")), "")

    next_line = next((l for l in lines[idx + 2 : idx + 30] if "next map is" in l.lower()), "")
    m = re.search(r"next map is\s+(.*?),\s*from\s+(.*)$", next_line, re.I)

    if not (current_from and m):
        sample = "\n".join(lines[idx : idx + 50])
        raise RuntimeError("BR Ranked ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n---DEBUG---\n" + sample)

    next_name = m.group(1).strip()
    next_detail = "From " + m.group(2).strip()

    return {"name": current_name, "detail": current_from}, {"name": next_name, "detail": next_detail}



def _slug_candidates(map_name: str):
    base = map_name.strip()
    base = base.replace("â€™", "").replace("'", "")  # ã‚¢ãƒã‚¹ãƒˆãƒ­ãƒ•ã‚£é™¤å»
    base = re.sub(r"\s+", " ", base)

    c1 = base.replace(" ", "_")  # ã‚¹ãƒšãƒ¼ã‚¹â†’_
    c2 = c1.replace("-", "_")    # -â†’_
    c3 = c1.replace("-", "")     # -é™¤å»
    c4 = c2.replace("_", "")     # _é™¤å»ï¼ˆEDistrictã¿ãŸã„ãªå½¢ï¼‰

    candidates = [c1, c2, c3, c4]

    cleaned = []
    seen = set()
    for c in candidates:
        c = re.sub(r"[^A-Za-z0-9_\-]", "", c)
        if c and c not in seen:
            seen.add(c)
            cleaned.append(c)

    return cleaned


def find_map_image_url(map_name: str):
    cands = _slug_candidates(map_name)
    if not cands:
        return None
    # å…ˆé ­å€™è£œã‚’ãã®ã¾ã¾ä½¿ã†ï¼ˆDiscordãŒå–å¾—ã—ã¦è¡¨ç¤ºã™ã‚‹ï¼‰
    return f"{ALS_ASSET_BASE}{cands[0]}.png"



def post_to_discord(webhook_url: str, current: dict, next_map: dict | None, image_url: str | None):
    now_jst = datetime.now(timezone.utc).astimezone(timezone(timedelta(hours=9)))

    cur_en = current["name"]
    cur_ja = JA_MAP.get(cur_en, cur_en)

    desc = f"**{cur_ja}**ï¼ˆ{cur_en}ï¼‰\n{current['detail']}"
    embed = {
        "title": "ğŸ—ºï¸ Apex ãƒ©ãƒ³ã‚¯ï¼ˆBRï¼‰ ç¾åœ¨ã®ãƒãƒƒãƒ—",
        "url": ALS_RANKED_URL,
        "description": desc,
        "timestamp": now_jst.isoformat(),
        "footer": {"text": "Data: Apex Legends Status"},
    }

    if next_map:
        nxt_en = next_map["name"]
        nxt_ja = JA_MAP.get(nxt_en, nxt_en)
        embed["fields"] = [
            {
                "name": "æ¬¡ã®ãƒãƒƒãƒ—",
                "value": f"**{nxt_ja}**ï¼ˆ{nxt_en}ï¼‰\n{next_map['detail']}",
                "inline": False,
            }
        ]

    if image_url:
        embed["image"] = {"url": image_url}

    payload = {
        "username": "Apex Ranked Map",
        "embeds": [embed],
        "allowed_mentions": {"parse": []},
    }

    res = requests.post(webhook_url, json=payload, timeout=25)
    res.raise_for_status()


def main():
    webhook_url = os.environ.get("DISCORD_WEBHOOK_URL")
    if not webhook_url:
        raise RuntimeError("ç’°å¢ƒå¤‰æ•° DISCORD_WEBHOOK_URL ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆGitHub Secrets ã‚’ç¢ºèªï¼‰")

    current, next_map = fetch_ranked_rotation()
    image_url = find_map_image_url(current["name"])

    post_to_discord(webhook_url, current, next_map, image_url)


if __name__ == "__main__":
    main()
